{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aeee0bf-5afb-40b6-af8e-bbf8c222b82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'filter_talon_transcripts' from '__main__' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-adb0ad0bde9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_talon_transcripts\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdstruct\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdstruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlength_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpost_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mputils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mqutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'filter_talon_transcripts' from '__main__' (unknown location)"
     ]
    }
   ],
   "source": [
    "from . import filter_talon_transcripts as filt\n",
    "from .. import dstruct as dstruct\n",
    "from .. import length_utils as lu\n",
    "from . import post_utils as putils\n",
    "from .. import query_utils as qutils\n",
    "from .. import talon as talon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3af8465-9060-4cf9-8921-7fdb6133d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba89581a-f899-4870-8885-de2371f4aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TALON: Techonology-Agnostic Long Read Analysis Pipeline\n",
    "# Author: Dana Wyman\n",
    "# -----------------------------------------------------------------------------\n",
    "# Queries for interacting with a TALON database\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# TALON: Techonology-Agnostic Long Read Analysis Pipeline\n",
    "# Author: Dana Wyman\n",
    "# -----------------------------------------------------------------------------\n",
    "# Queries for working with exon and transcript lengths\n",
    "\n",
    "def get_all_exon_lengths(cursor, build):\n",
    "    \"\"\" Compute all exon lengths and store in a dict \"\"\"\n",
    "\n",
    "    exon_lengths = {}\n",
    "    cursor.execute(\"\"\" SELECT edge_ID,\n",
    "                          loc1.position AS pos1,\n",
    "                          loc2.position AS pos2,\n",
    "                          abs(loc1.position - loc2.position) + 1 AS diff\n",
    "                       FROM edge \n",
    "                       LEFT JOIN location AS loc1 ON edge.v1 = loc1.location_ID\n",
    "                       LEFT JOIN location AS loc2 ON edge.v2 = loc2.location_ID\n",
    "                       WHERE edge_type = 'exon' \n",
    "                       AND loc1.genome_build = '%s'\n",
    "                       AND loc2.genome_build = '%s' \"\"\" % (build, build))\n",
    "\n",
    "    for exon in cursor.fetchall():\n",
    "        exon_ID = exon['edge_ID']\n",
    "        length = exon['diff']\n",
    "        exon_lengths[exon_ID] = length\n",
    "\n",
    "    return exon_lengths\n",
    "\n",
    "def get_transcript_length(transcript_row, exon_lengths):\n",
    "    \"\"\" Compute the length of the supplied transcript model based on its\n",
    "        exons. Expected input format consists of a transcript row from a\n",
    "        TALON database. \"\"\"\n",
    "\n",
    "    length = 0\n",
    "    start_exon = transcript_row['start_exon']\n",
    "    end_exon = transcript_row['end_exon']\n",
    "    n_exons = transcript_row['n_exons']\n",
    "\n",
    "    if n_exons == 1:\n",
    "        return exon_lengths[start_exon]\n",
    "    else:\n",
    "        jn_path =  transcript_row['jn_path'].split(\",\")\n",
    "        all_exons = [start_exon] + [int(x) for x in jn_path[1::2]] + [end_exon]\n",
    "       \n",
    "        for exon in all_exons:\n",
    "            length += exon_lengths[exon]\n",
    "\n",
    "        return length\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def fetch_reproducible_intergenic(cursor, datasets):\n",
    "    \"\"\" Return the gene and transcript ID of any intergenic transcripts that were\n",
    "        found in at least two of the supplied datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'intergenic_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    intergenic = [(x[0], x[1], \"intergenic_transcript\") for x in cursor.fetchall()]\n",
    "    return intergenic\n",
    "\n",
    "def fetch_reproducible_antisense(cursor, datasets):\n",
    "    \"\"\" Return the gene and transcript ID of any antisense transcripts that were\n",
    "        found in at least two of the supplied datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'antisense_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    antisense = [(x[0], x[1], \"antisense_transcript\") for x in cursor.fetchall()]\n",
    "    return antisense\n",
    "\n",
    "def fetch_reproducible_NNCs(cursor, datasets):\n",
    "    \"\"\" Return the gene and transcript ID of any NNC transcripts that were\n",
    "        found in at least two of the supplied datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT gene_ID, \n",
    "                      a.transcript_ID \n",
    "               FROM abundance as a\n",
    "\t       LEFT JOIN transcript_annotations as ta\n",
    "\t           ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "\t           ON transcripts.transcript_ID = a.transcript_ID\n",
    "\t       WHERE ta.attribute = 'NNC_transcript'\n",
    "\t       AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    NNC = [(x[0], x[1], \"NNC_transcript\") for x in cursor.fetchall()]\n",
    "    return NNC\n",
    "\n",
    "def fetch_reproducible_NICs(cursor, datasets):\n",
    "    \"\"\" Return the gene and transcript ID of any NIC transcripts that were\n",
    "        found in at least two of the supplied datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'NIC_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    NIC = [(x[0], x[1], \"NIC_transcript\") for x in cursor.fetchall()]\n",
    "    return NIC\n",
    "\n",
    "def fetch_reproducible_ISMs(cursor, datasets):\n",
    "    \"\"\" Return the gene and transcript ID of any ISM transcripts that were\n",
    "        found in at least two of the supplied datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    transcripts_seen = {}\n",
    "\n",
    "    # To label novelty, perform queries separately for suffix, prefix, and\n",
    "    # regular ISMs\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'ISM-prefix_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    ISMs = [(x[0], x[1], \"ISM-prefix_transcript\") for x in cursor.fetchall()]\n",
    "\n",
    "    for entry in ISMs:\n",
    "        transcripts_seen[entry[1]] = 1\n",
    "\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'ISM-suffix_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    suffix_ISMs = [(x[0], x[1], \"ISM-suffix_transcript\") for x in cursor.fetchall()]\n",
    "    # Only add suffix ISM transcript if it isn't already on the list\n",
    "    for entry in suffix_ISMs:\n",
    "        if entry[1] not in transcripts_seen:\n",
    "            ISMs.append(entry)\n",
    "            transcripts_seen[entry[1]] = 1\n",
    "\n",
    "    query = \"\"\"SELECT gene_ID,\n",
    "                      a.transcript_ID\n",
    "               FROM abundance as a\n",
    "               LEFT JOIN transcript_annotations as ta\n",
    "                   ON ta.ID = a.transcript_ID\n",
    "               LEFT JOIN transcripts\n",
    "                   ON transcripts.transcript_ID = a.transcript_ID\n",
    "               WHERE ta.attribute = 'ISM_transcript'\n",
    "               AND a.dataset IN \"\"\" + datasets + \\\n",
    "           \"\"\" GROUP BY a.transcript_ID\n",
    "               HAVING count(*) > 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    all_ISMs = [(x[0], x[1], \"other_ISM_transcript\") for x in cursor.fetchall()]\n",
    "    # Only add ISM transcript if it isn't already on the list\n",
    "    for entry in all_ISMs:\n",
    "        if entry[1] not in transcripts_seen:\n",
    "            ISMs.append(entry)\n",
    "            transcripts_seen[entry[1]] = 1\n",
    "\n",
    "    return ISMs\n",
    "\n",
    "def fetch_known_transcripts_with_gene_label(cursor, datasets):\n",
    "    \"\"\" Fetch known transcripts along with the gene they belong to \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT gene_ID,transcript_ID FROM observed\n",
    "                   LEFT JOIN transcript_annotations AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'transcript_status' AND ta.value = 'KNOWN')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    known_transcripts = [(x[0], x[1], \"FSM_transcript\") for x in cursor.fetchall()]\n",
    "    return known_transcripts\n",
    "\n",
    "def fetch_NIC_transcripts_with_gene_label(cursor, datasets):\n",
    "    \"\"\" Fetch NIC transcripts along with the gene they belong to \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT gene_ID,transcript_ID FROM observed\n",
    "                   LEFT JOIN transcript_annotations AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'NIC_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    known_transcripts = [(x[0], x[1], \"NIC_transcript\") for x in cursor.fetchall()]\n",
    "    return known_transcripts\n",
    "\n",
    "def count_observed_reads(cursor, datasets):\n",
    "    \"\"\" Count the number of observed reads for the provided datasets \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"SELECT COUNT(obs_ID) FROM observed WHERE dataset IN \" + datasets\n",
    "    cursor.execute(query)\n",
    "    reads = cursor.fetchone()[0]\n",
    "    return reads\n",
    "\n",
    "def fetch_all_known_genes_detected(cursor, datasets):\n",
    "    \"\"\" Get the IDs of all known genes found in a particular dataset (no \n",
    "        filter with respect to the type of transcript detected). \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(gene_ID) FROM observed\n",
    "                   LEFT JOIN gene_annotations AS ga ON ga.ID = observed.gene_ID\n",
    "                   WHERE (ga.attribute = 'gene_status' AND ga.value = 'KNOWN')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    known_genes = [x[0] for x in cursor.fetchall()]\n",
    "    return known_genes\n",
    "\n",
    "def count_known_genes_detected(cursor, dataset):\n",
    "    \"\"\" Count the number of known genes detected in the dataset (no filter\n",
    "        with respect to the type of transcript detected). \"\"\"\n",
    "\n",
    "    known_genes = fetch_all_known_genes_detected(cursor, dataset)\n",
    "    return len(known_genes)\n",
    "\n",
    "def count_novel_genes_detected(cursor, dataset):\n",
    "    \"\"\" Count the number of novel genes detected in the dataset (no filter\n",
    "        with respect to the type of transcript detected). \"\"\"\n",
    "\n",
    "    novel_genes = fetch_all_novel_genes_detected(cursor, dataset)\n",
    "    return len(novel_genes)\n",
    "\n",
    "def fetch_all_novel_genes_detected(cursor, datasets):\n",
    "    \"\"\" Get the IDs of all novel genes found in a particular dataset (no\n",
    "        filter with respect to the type of transcript detected). \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(gene_ID) FROM observed\n",
    "                   LEFT JOIN gene_annotations AS ga ON ga.ID = observed.gene_ID\n",
    "                   WHERE (ga.attribute = 'gene_status' AND ga.value = 'NOVEL')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    novel_genes = [x[0] for x in cursor.fetchall()]\n",
    "    return novel_genes\n",
    "\n",
    "def fetch_all_known_transcripts_detected(cursor, datasets):\n",
    "    \"\"\" Get the IDs of all transcripts annotated as known. Does not include \n",
    "        novel FSMs \"\"\"\n",
    " \n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'transcript_status' AND ta.value = 'KNOWN')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    known_transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return known_transcripts\n",
    "\n",
    "def fetch_FSM_novel_transcripts(cursor, dataset):\n",
    "    \"\"\" Fetch IDs of novel FSMs observed in the current dataset \"\"\"\n",
    "\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'FSM_transcript' AND ta.value = 'TRUE')\n",
    "                   AND observed.dataset = ?;\"\"\"\n",
    "    cursor.execute(query, [dataset])\n",
    "    FSM_transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return FSM_transcripts\n",
    "\n",
    "def fetch_novel_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of novel transcripts observed in the current dataset \"\"\"\n",
    "    datasets = format_for_IN(datasets)\n",
    "\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'transcript_status' AND ta.value = 'NOVEL')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_antisense_genes(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of antisense genes observed in the dataset(s) \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(gene_ID) FROM observed\n",
    "                   LEFT JOIN gene_annotations AS ga ON ga.ID = observed.gene_ID\n",
    "                   WHERE (ga.attribute = 'antisense_gene')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    genes = [x[0] for x in cursor.fetchall()]\n",
    "    return genes\n",
    "\n",
    "def fetch_intergenic_novel_genes(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of novel genes denoted as intergenic \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(gene_ID) FROM observed\n",
    "                   LEFT JOIN gene_annotations AS ga ON ga.ID = observed.gene_ID\n",
    "                   WHERE (ga.attribute = 'intergenic_novel')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    genes = [x[0] for x in cursor.fetchall()]\n",
    "    return genes\n",
    "\n",
    "def fetch_all_ISM_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all ISM transcripts \"\"\"\n",
    "    \n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations \n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'ISM_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_prefix_ISM_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all ISM prefix transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'ISM-prefix_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_suffix_ISM_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all ISM suffix transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'ISM-suffix_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_NIC_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all NIC transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'NIC_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_NNC_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all NNC transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'NNC_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_antisense_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all antisense transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'antisense_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_intergenic_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all intergenic transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'intergenic_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "\n",
    "def fetch_genomic_transcripts(cursor, datasets):\n",
    "    \"\"\" Fetch IDs of all genomic transcripts \"\"\"\n",
    "\n",
    "    datasets = format_for_IN(datasets)\n",
    "    query = \"\"\"SELECT DISTINCT(transcript_ID) FROM observed\n",
    "                   LEFT JOIN transcript_annotations\n",
    "                       AS ta ON ta.ID = observed.transcript_ID\n",
    "                   WHERE (ta.attribute = 'genomic_transcript')\n",
    "                   AND observed.dataset IN \"\"\" + datasets\n",
    "    cursor.execute(query)\n",
    "    transcripts = [x[0] for x in cursor.fetchall()]\n",
    "    return transcripts\n",
    "\n",
    "def fetch_all_transcript_gene_pairs(cursor):\n",
    "    \"\"\" Return gene_ID - transcript_ID tuples from database \"\"\"\n",
    "\n",
    "    query = \"\"\" SELECT gene_ID, transcript_ID FROM transcripts \"\"\"\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    pairs = cursor.fetchall()\n",
    "    return pairs\n",
    "    \n",
    "def fetch_all_datasets(cursor):\n",
    "    \"\"\" Return a list of all datasets in database \"\"\"\n",
    "    cursor.execute(\"SELECT dataset_name FROM dataset\")\n",
    "    datasets = [str(x[0]) for x in cursor.fetchall()]\n",
    "    return datasets\n",
    "\n",
    "def parse_whitelist(whitelist_file):\n",
    "    \"\"\" From the whitelist file, obtain a list of acccepted gene and \n",
    "        transcript IDs tuples\"\"\"\n",
    "    whitelist = set()\n",
    "    with open(whitelist_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            fields = line.split(\",\")\n",
    "            gene_ID = fields[0]\n",
    "            transcript_ID = fields[1]\n",
    "            try:\n",
    "                whitelist.add((int(gene_ID), int(transcript_ID)))\n",
    "            except:\n",
    "                raise ValueError(\"Gene/Transcript IDs in whitelist must be integer TALON IDs\")\n",
    "    return whitelist\n",
    "\n",
    "def parse_datasets(dataset_file, cursor):\n",
    "    \"\"\" From the dataset file, obtain a list of acccepted dataset names\"\"\"\n",
    "    # Get datasets in this database\n",
    "    db_datasets = fetch_all_datasets(cursor)\n",
    "\n",
    "    dataset_list = set()\n",
    "    with open(dataset_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            fields = line.split()\n",
    "            dataset = fields[0]\n",
    "            if dataset not in db_datasets:\n",
    "                raise ValueError(\"Dataset name '%s' not found in database\" % dataset)\n",
    "            dataset_list.add(dataset)\n",
    "    return dataset_list\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "def format_for_IN(l):\n",
    "    \"\"\" Converts input to string that can be used for IN database query \"\"\"\n",
    "    \n",
    "    if type(l) is tuple:\n",
    "        l = list(l)\n",
    "    if type(l) is str:\n",
    "        l = [l]\n",
    "\n",
    "    return \"(\" + ','.join(['\"' + str(x) + '\"' for x in l]) + \")\" \n",
    "\n",
    "\n",
    "def handle_filtering(database, annot, observed, whitelist_file, dataset_file):\n",
    "    \"\"\" Determines which transcripts to allow in the analysis. This can be done\n",
    "        in two different ways. If no whitelist is included, then all of the\n",
    "        transcripts in the database are included (modified by 'observed'\n",
    "        option). If a whitelist is provided, then transcripts on that list\n",
    "        will be included (modified by 'observed' option). This can be\n",
    "        tuned further by providing a dataset file, but this is optional. \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get list of datasets to use in run\n",
    "    if dataset_file != None:\n",
    "        datasets = parse_datasets(dataset_file, cursor)\n",
    "    elif observed == True:\n",
    "        datasets = fetch_all_datasets(cursor)\n",
    "    else:\n",
    "        datasets = None\n",
    "\n",
    "    # Get initial transcript whitelist\n",
    "    if whitelist_file != None:\n",
    "        whitelist = parse_whitelist(whitelist_file)\n",
    "    else:\n",
    "        whitelist = fetch_all_transcript_gene_pairs(cursor)\n",
    "\n",
    "    if datasets != None:\n",
    "        # Limit the whitelist to transcripts detected in the datasets\n",
    "        transcripts = [ x[1] for x in whitelist ]\n",
    "        transcript_str = format_for_IN(transcripts)\n",
    "        dataset_str = format_for_IN(datasets)\n",
    "\n",
    "        query = \"\"\" SELECT DISTINCT gene_ID, transcript_ID\n",
    "                    FROM observed\n",
    "                    WHERE transcript_ID IN %s\n",
    "                    AND dataset in %s \"\"\"\n",
    "        cursor.execute(query % (transcript_str, dataset_str))\n",
    "        whitelist = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "    return whitelist\n",
    "\n",
    "def fetch_dataset_list(dataset_file, database):\n",
    "    \"\"\" Gets a list of all datasets in the database \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    cursor = conn.cursor()\n",
    "    all_db_datasets = fetch_all_datasets(cursor)\n",
    "    conn.close()\n",
    "\n",
    "    if dataset_file == None:\n",
    "\n",
    "        return all_db_datasets\n",
    "\n",
    "    else:\n",
    "        datasets = []\n",
    "        with open(dataset_file, 'r') as f:\n",
    "            for line in f:\n",
    "                dataset = line.strip()\n",
    "                if dataset not in all_db_datasets:\n",
    "                    raise ValueError(\"Dataset name '%s' not found in database\" \\\n",
    "                                      % (dataset))\n",
    "                datasets.append(dataset)\n",
    "\n",
    "        return datasets\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89f97418-ef70-434b-82ad-f818d1e69ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_names(gene_ID, transcript_ID, prefix, n_places):\n",
    "    \"\"\" Create a gene and transcript name using the TALON IDs.\n",
    "        The n_places variable indicates how many characters long the numeric\n",
    "        part of the name should be. \"\"\"\n",
    "\n",
    "    gene_ID_str = str(gene_ID).zfill(n_places)\n",
    "    gene_name = prefix + \"G\" + gene_ID_str\n",
    "\n",
    "    transcript_ID_str = str(transcript_ID).zfill(n_places)\n",
    "    transcript_name = prefix + \"T\" + transcript_ID_str\n",
    "\n",
    "    return gene_name, transcript_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "daddff01-1374-4f70-9d17-74c7b88b24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct(dict):\n",
    "    \"\"\"\n",
    "    Make a dict behave as a struct.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "        test = Struct(a=1, b=2, c=3)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,**kw):\n",
    "        dict.__init__(self,kw)\n",
    "        self.__dict__ = self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50afc148-5992-42f4-8b54-837c07116d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from create_abundance_file that need to go in its own \n",
    "# file later jeez\n",
    "\n",
    "def get_transcript_lengths(database, build):\n",
    "    \"\"\" Read the transcripts from the database. Then compute the lengths.\n",
    "        Store in a dictionary \"\"\"\n",
    "\n",
    "    transcript_lengths = {}\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get the exon lengths\n",
    "    exon_lens = get_all_exon_lengths(cursor, build)\n",
    "\n",
    "    cursor.execute(\"SELECT * FROM transcripts\")\n",
    "    for transcript_row in cursor.fetchall():\n",
    "        transcript_ID = transcript_row['transcript_ID']\n",
    "        length = get_transcript_length(transcript_row, exon_lens)\n",
    "        transcript_lengths[transcript_ID] = length\n",
    "\n",
    "    conn.close()\n",
    "    return transcript_lengths\n",
    "\n",
    "def fetch_naming_prefix(database):\n",
    "    \"\"\" Get naming prefix from the database run_info table \"\"\"\n",
    "    conn = sqlite3.connect(database)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT value FROM run_info WHERE item = 'idprefix'\")\n",
    "    prefix = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "    return prefix\n",
    "\n",
    "def fetch_n_places(database):\n",
    "    \"\"\" Get length of name field from the database run_info table \"\"\"\n",
    "    conn = sqlite3.connect(database)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT value FROM run_info WHERE item = 'n_places'\")\n",
    "    n_places = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "    return int(n_places)\n",
    "\n",
    "def fetch_dataset_list(dataset_file, database):\n",
    "    \"\"\" Gets a list of all datasets in the database \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    cursor = conn.cursor()\n",
    "    all_db_datasets = fetch_all_datasets(cursor)\n",
    "    conn.close()\n",
    "\n",
    "    if dataset_file == None:\n",
    "\n",
    "        return all_db_datasets\n",
    "\n",
    "    else:\n",
    "        datasets = []\n",
    "        with open(dataset_file, 'r') as f:\n",
    "            for line in f:\n",
    "                dataset = line.strip()\n",
    "                if dataset not in all_db_datasets:\n",
    "                    raise ValueError(\"Dataset name '%s' not found in database\" \\\n",
    "                                      % (dataset))\n",
    "                datasets.append(dataset)\n",
    "\n",
    "        return datasets\n",
    "    \n",
    "    \n",
    "def make_novelty_type_struct(database, datasets):\n",
    "    \"\"\" Create a data structure where it is possible to look up whether a gene\n",
    "        or transcript belongs to a particular category of novelty\"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    novelty_type = Struct()\n",
    "    novelty_type.known_genes = set(fetch_all_known_genes_detected(cursor, datasets))\n",
    "    novelty_type.antisense_genes = set(fetch_antisense_genes(cursor, datasets))\n",
    "    novelty_type.intergenic_genes = set(fetch_intergenic_novel_genes(cursor, datasets))\n",
    "    novelty_type.known_transcripts = set(fetch_all_known_transcripts_detected(cursor, datasets))\n",
    "    novelty_type.ISM_transcripts = set(fetch_all_ISM_transcripts(cursor, datasets))\n",
    "    novelty_type.ISM_prefix = set(fetch_prefix_ISM_transcripts(cursor, datasets))\n",
    "    novelty_type.ISM_suffix = set(fetch_suffix_ISM_transcripts(cursor, datasets))\n",
    "    novelty_type.NIC_transcripts = set(fetch_NIC_transcripts(cursor, datasets))\n",
    "    novelty_type.NNC_transcripts = set(fetch_NNC_transcripts(cursor, datasets))\n",
    "    novelty_type.antisense_transcripts = set(fetch_antisense_transcripts(cursor, datasets))\n",
    "    novelty_type.intergenic_transcripts = set(fetch_intergenic_transcripts(cursor, datasets))\n",
    "    novelty_type.genomic_transcripts = set(fetch_genomic_transcripts(cursor, datasets))\n",
    "\n",
    "    conn.close()\n",
    "    return novelty_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "287472b9-90df-45a8-8bdd-ba79639e115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fd23135-2900-4a78-9ea2-882d0072fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_list = '/Users/fairliereese/Documents/programming/mortazavi_lab/data/mousewg/hippocampus/lr_splitseq/talon/test_pass_list.csv'\n",
    "db = '/Users/fairliereese/Documents/programming/mortazavi_lab/data/mousewg/hippocampus/lr_splitseq/talon/hippocampus.db'\n",
    "annot = 'gencode_vM21'\n",
    "# dataset_file = '/Users/fairliereese/mortazavi_lab/data/mousewg/hippocampus/lr_splitseq/talon/dataset_file.tsv'\n",
    "dataset_file = None\n",
    "build = 'mm10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f10c3e27-2d3a-48f9-bb91-eb326466e00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a27e76ee-deaf-4565-a3c7-257ce440fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_lengths = pd.DataFrame.from_dict(transcript_lengths, orient='index', columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9cbdaa06-1384-4490-8c09-e826e3a6c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nov_ids_dict(df, d):\n",
    "    \"\"\"\n",
    "    Get a novelty dict for transcripts / genes \n",
    "    based on column mapping / values from df\n",
    "    \"\"\"\n",
    "    nov_dict = {}\n",
    "    for key, val in d.items():\n",
    "        nov_dict[key] = df.loc[(df.attribute==val[0])&(df.value==val[1]), 'ID'].tolist()\n",
    "    return nov_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4bff0312-37a3-4c2d-b5ed-d2a4908ccaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_t_names(db, annot):\n",
    "    \"\"\"\n",
    "    Get names of genes / transcripts\n",
    "    \"\"\"\n",
    "\n",
    "    # get information that we want for each transcript, stuff that \n",
    "    # would be output in the abundance table\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            t.gene_ID,\n",
    "            t.transcript_ID,\n",
    "            ga_id.value AS annot_gene_id,\n",
    "            ta_id.value AS annot_transcript_id,\n",
    "            ga_name.value AS annot_gene_name,\n",
    "            ta_name.value AS annot_transcript_name,\n",
    "            t.n_exons\n",
    "        FROM transcripts t\n",
    "            LEFT JOIN gene_annotations ga_id ON t.gene_ID = ga_id.ID\n",
    "                AND ga_id.annot_name = '%s'\n",
    "                AND ga_id.attribute = 'gene_id'\n",
    "            LEFT JOIN transcript_annotations ta_id ON t.transcript_ID = ta_id.ID\n",
    "                AND ta_id.annot_name = '%s'\n",
    "                AND ta_id.attribute = 'transcript_id'\n",
    "            LEFT JOIN gene_annotations ga_name ON t.gene_ID = ga_name.ID\n",
    "                AND ga_name.annot_name = '%s'\n",
    "                    AND ga_name.attribute = 'gene_name'\n",
    "            LEFT JOIN transcript_annotations ta_name ON t.transcript_ID = ta_name.ID\n",
    "                AND ta_name.annot_name = '%s'\n",
    "                    AND ta_name.attribute = 'transcript_name'\n",
    "        \"\"\" % (annot, annot, annot, annot)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "58e33ee3-d831-4409-b64b-dacf56d4957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_novelties(df, d, order, how):\n",
    "    \n",
    "    if how == 'gene':\n",
    "        nov_col = 'gene_novelty'\n",
    "        cols = [nov_col]\n",
    "    elif how == 'transcript':\n",
    "        nov_col = 'transcript_novelty'\n",
    "        cols = [nov_col, 'ISM_subtype']\n",
    "    \n",
    "    # assign gene or transcript novelty\n",
    "    df = df.pivot(index='ID', columns=['attribute'], values=['value'])\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    df.columns.name = ''\n",
    "\n",
    "    for key, value in d.items():\n",
    "        df[key] = False\n",
    "        df.loc[df[value[0]]==value[1], key] = True\n",
    "        df.drop(value[0], axis=1, inplace=True)\n",
    "        \n",
    "    df[nov_col] = np.nan\n",
    "    for o in order:\n",
    "        df.loc[(df[nov_col].isnull())&(df[o]==True), nov_col] = o\n",
    "    \n",
    "    # assign ism subtype if needed\n",
    "    if how == 'transcript':\n",
    "        df['ISM_subtype'] = np.nan\n",
    "        df.loc[(df.ISM_subtype.isnull())&(df['ISM-prefix'])&(df['ISM-suffix']), 'ISM_subtype'] = 'Both'\n",
    "        df.loc[(df.ISM_subtype.isnull())&(df['ISM-prefix']), 'ISM_subtype'] = 'Prefix'\n",
    "        df.loc[(df.ISM_subtype.isnull())&(df['ISM-suffix']), 'ISM_subtype'] = 'Suffix'\n",
    "        df.loc[df.ISM_subtype.isnull(), 'ISM_subtype'] = 'None'\n",
    "    \n",
    "    # reduce cols\n",
    "    df = df[cols]\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bef12257-de66-4082-8b11-3a8914a62a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript_novs(db):\n",
    "    nov_col_dict = {'Known': ('transcript_status', 'KNOWN'),\n",
    "                    'ISM': ('ISM_transcript', 'TRUE'),\n",
    "                    'ISM-prefix': ('ISM-prefix_transcript', 'TRUE'),\n",
    "                    'ISM-suffix': ('ISM-suffix_transcript', 'TRUE'),\n",
    "                    'NIC': ('NIC_transcript', 'TRUE'),\n",
    "                    'NNC': ('NNC_transcript', 'TRUE'),\n",
    "                    'Antisense': ('antisense_transcript', 'TRUE'),\n",
    "                    'Intergenic': ('intergenic_transcript', 'TRUE'),\n",
    "                    'Genomic': ('genomic_transcript', 'TRUE')}\n",
    "    order = ['ISM', 'NIC', 'NNC', 'Antisense', \n",
    "             'Intergenic', 'Genomic', 'Known']\n",
    "\n",
    "    attr_list = [val[0] for key, val in nov_col_dict.items()]\n",
    "    attrs = format_for_IN(attr_list)\n",
    "    \n",
    "    with sqlite3.connect(db) as conn:\n",
    "        query = f\"\"\"SELECT ID, attribute, value\n",
    "                    FROM transcript_annotations \n",
    "                    WHERE attribute IN {attrs}\n",
    "                 \"\"\"\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        \n",
    "    df = assign_novelties(df, nov_col_dict, order, 'transcript')\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dca9c756-61ca-4356-b2fb-71532c8192a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_novs(db):\n",
    "    nov_col_dict = {'Known': ('gene_status', 'KNOWN'),\n",
    "                   'Intergenic': ('intergenic_novel', 'TRUE'),\n",
    "                   'Antisense': ('antisense_gene', 'TRUE')}\n",
    "    order = ['Antisense', 'Intergenic', 'Known']\n",
    "    \n",
    "    attr_list = [val[0] for key, val in nov_col_dict.items()]\n",
    "    attrs = format_for_IN(attr_list)\n",
    "    \n",
    "    with sqlite3.connect(db) as conn:\n",
    "        query = f\"\"\"SELECT ID, attribute, value\n",
    "                    FROM gene_annotations \n",
    "                    WHERE attribute IN {attrs}\n",
    "                 \"\"\"\n",
    "        df = pd.read_sql_query(query, conn) \n",
    "    df = assign_novelties(df, nov_col_dict, order, 'gene')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "17dfea1d-7c83-4a2d-9d0c-1212cfdb4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_info(db, annot, build):\n",
    "    \n",
    "    # get names / ids of transcripts / genes\n",
    "    df = get_g_t_names(db, annot)\n",
    "    prefix = fetch_naming_prefix(db)\n",
    "    n_places = fetch_n_places(db)\n",
    "\n",
    "    # add gene / transcript names / ids\n",
    "    df[['temp_gid', 'temp_tid']] = df.apply(lambda x: construct_names(x.gene_ID,\n",
    "                         x.transcript_ID,\n",
    "                         prefix,\n",
    "                         n_places), \n",
    "                     axis=1, result_type='expand')\n",
    "\n",
    "    # replace null gene names / ids\n",
    "    inds = df.loc[df.annot_gene_id.isnull()].index\n",
    "    df.loc[inds, 'annot_gene_id'] = df.loc[inds, 'temp_gid']\n",
    "    inds = df.loc[df.annot_gene_name.isnull()].index\n",
    "    df.loc[inds, 'annot_gene_name'] = df.loc[inds, 'temp_gid']\n",
    "\n",
    "    # replace null transcript names / ids\n",
    "    inds = df.loc[df.annot_transcript_id.isnull()].index\n",
    "    df.loc[inds, 'annot_transcript_id'] = df.loc[inds, 'temp_tid']\n",
    "    inds = df.loc[df.annot_transcript_name.isnull()].index\n",
    "    df.loc[inds, 'annot_transcript_name'] = df.loc[inds, 'temp_tid']\n",
    "\n",
    "    # remove temp cols\n",
    "    df.drop(['temp_gid', 'temp_tid'], axis=1, inplace=True)\n",
    "    \n",
    "    # add transcript len\n",
    "    t_lens = pd.DataFrame.from_dict(get_transcript_lengths(db, build),\n",
    "                                                orient='index',\n",
    "                                                columns=['length'])\n",
    "    df = df.merge(t_lens, how='left', left_on='transcript_ID', right_index=True)\n",
    "    \n",
    "    # add gene novelty\n",
    "    g_df = get_gene_novs(db)\n",
    "    df = df.merge(g_df, how='left', left_on='gene_ID', right_on='ID')\n",
    "    df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "    # add transcript novelty / ism subtype\n",
    "    t_df = get_transcript_novs(db)\n",
    "    df = df.merge(t_df, how='left', left_on='transcript_ID', right_on='ID')\n",
    "    df.drop('ID', axis=1, inplace=True)\n",
    "    \n",
    "    # column order \n",
    "    order = ['gene_ID', 'transcript_ID', 'annot_gene_id', \n",
    "             'annot_transcript_id', 'annot_gene_name',\n",
    "             'annot_transcript_name', 'n_exons', 'length',\n",
    "             'gene_novelty', 'transcript_novelty', 'ISM_subtype']\n",
    "    df = df[order]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "acbcfabb-05b8-4bb9-88bc-1d69a5d03b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_var_info(db, annot, build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe51d45-abec-4489-a377-086b01101240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454dffc-51d4-491e-9461-0438ad82df06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b4a90-e634-423a-926e-7a39e4b836bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1bae7b6e-f6a3-492c-b93c-b95744614b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names / ids of transcripts / genes\n",
    "df = get_g_t_names(db, annot)\n",
    "prefix = fetch_naming_prefix(db)\n",
    "n_places = fetch_n_places(db)\n",
    "\n",
    "# add gene / transcript names / ids\n",
    "df[['temp_gid', 'temp_tid']] = df.apply(lambda x: construct_names(x.gene_ID,\n",
    "                     x.transcript_ID,\n",
    "                     prefix,\n",
    "                     n_places), \n",
    "                 axis=1, result_type='expand')\n",
    "\n",
    "# replace null gene names / ids\n",
    "inds = df.loc[df.annot_gene_id.isnull()].index\n",
    "df.loc[inds, 'annot_gene_id'] = df.loc[inds, 'temp_gid']\n",
    "inds = df.loc[df.annot_gene_name.isnull()].index\n",
    "df.loc[inds, 'annot_gene_name'] = df.loc[inds, 'temp_gid']\n",
    "\n",
    "# replace null transcript names / ids\n",
    "inds = df.loc[df.annot_transcript_id.isnull()].index\n",
    "df.loc[inds, 'annot_transcript_id'] = df.loc[inds, 'temp_tid']\n",
    "inds = df.loc[df.annot_transcript_name.isnull()].index\n",
    "df.loc[inds, 'annot_transcript_name'] = df.loc[inds, 'temp_tid']\n",
    "\n",
    "# remove temp cols\n",
    "df.drop(['temp_gid', 'temp_tid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "28fb43e8-8a79-4a9c-8209-e7196add7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add transcript len\n",
    "t_lens = pd.DataFrame.from_dict(get_transcript_lengths(db, build),\n",
    "                                            orient='index',\n",
    "                                            columns=['length'])\n",
    "df = df.merge(t_lens, how='left', left_on='transcript_ID', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "670271ce-2083-4411-b139-9b75790a3213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ID</th>\n",
       "      <th>transcript_ID</th>\n",
       "      <th>annot_gene_id</th>\n",
       "      <th>annot_transcript_id</th>\n",
       "      <th>annot_gene_name</th>\n",
       "      <th>annot_transcript_name</th>\n",
       "      <th>n_exons</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSMUSG00000102693.1</td>\n",
       "      <td>ENSMUST00000193812.1</td>\n",
       "      <td>4933401J01Rik</td>\n",
       "      <td>4933401J01Rik-201</td>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSMUSG00000064842.1</td>\n",
       "      <td>ENSMUST00000082908.1</td>\n",
       "      <td>Gm26206</td>\n",
       "      <td>Gm26206-201</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000162897.1</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-203</td>\n",
       "      <td>2</td>\n",
       "      <td>4153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000159265.1</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-202</td>\n",
       "      <td>2</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000070533.4</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-201</td>\n",
       "      <td>3</td>\n",
       "      <td>3634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene_ID  transcript_ID         annot_gene_id   annot_transcript_id  \\\n",
       "0        1              1  ENSMUSG00000102693.1  ENSMUST00000193812.1   \n",
       "1        2              2  ENSMUSG00000064842.1  ENSMUST00000082908.1   \n",
       "2        3              3  ENSMUSG00000051951.5  ENSMUST00000162897.1   \n",
       "3        3              4  ENSMUSG00000051951.5  ENSMUST00000159265.1   \n",
       "4        3              5  ENSMUSG00000051951.5  ENSMUST00000070533.4   \n",
       "\n",
       "  annot_gene_name annot_transcript_name  n_exons  length  \n",
       "0   4933401J01Rik     4933401J01Rik-201        1    1070  \n",
       "1         Gm26206           Gm26206-201        1     110  \n",
       "2            Xkr4              Xkr4-203        2    4153  \n",
       "3            Xkr4              Xkr4-202        2    2989  \n",
       "4            Xkr4              Xkr4-201        3    3634  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "df337eb3-81ce-4b94-91ed-96b659947ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gene novelty\n",
    "g_df = get_gene_novs(db)\n",
    "df = df.merge(g_df, how='left', left_on='gene_ID', right_on='ID')\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# add transcript novelty / ism subtype\n",
    "t_df = get_transcript_novs(db)\n",
    "df = df.merge(t_df, how='left', left_on='transcript_ID', right_on='ID')\n",
    "df.drop('ID', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "53eedb1b-88f3-4c9e-89f5-ae5d5610a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636549\n",
      "636549\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gene_novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Known</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID gene_novelty\n",
       "0   1        Known\n",
       "1   2        Known\n",
       "2   3        Known\n",
       "3   4        Known\n",
       "4   5        Known"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(df.gene_ID))\n",
    "print(max(g_df.ID))\n",
    "print(min(df.gene_ID))\n",
    "print(min(g_df.ID))\n",
    "g_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e1226f71-b492-45cf-afb9-7654754ad921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2459184\n",
      "2459184\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>transcript_novelty</th>\n",
       "      <th>ISM_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Known</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Known</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Known</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Known</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Known</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID transcript_novelty ISM_subtype\n",
       "0   1              Known        None\n",
       "1   2              Known        None\n",
       "2   3              Known        None\n",
       "3   4              Known        None\n",
       "4   5              Known        None"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(df.transcript_ID))\n",
    "print(max(t_df.ID))\n",
    "print(min(df.transcript_ID))\n",
    "print(min(t_df.ID))\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f3e79abd-59f5-4e25-aef4-ac2dd7fb82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.length.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e424f11-fd98-4984-8af8-4ff1cf4f7785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ID</th>\n",
       "      <th>transcript_ID</th>\n",
       "      <th>annot_gene_id</th>\n",
       "      <th>annot_transcript_id</th>\n",
       "      <th>annot_gene_name</th>\n",
       "      <th>annot_transcript_name</th>\n",
       "      <th>n_exons</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141862</th>\n",
       "      <td>55537</td>\n",
       "      <td>141863</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141863</th>\n",
       "      <td>55538</td>\n",
       "      <td>141864</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141865</th>\n",
       "      <td>55538</td>\n",
       "      <td>141866</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141866</th>\n",
       "      <td>55539</td>\n",
       "      <td>141867</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141867</th>\n",
       "      <td>55540</td>\n",
       "      <td>141868</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gene_ID  transcript_ID annot_gene_id annot_transcript_id  \\\n",
       "141862    55537         141863          None                None   \n",
       "141863    55538         141864          None                None   \n",
       "141865    55538         141866          None                None   \n",
       "141866    55539         141867          None                None   \n",
       "141867    55540         141868          None                None   \n",
       "\n",
       "       annot_gene_name annot_transcript_name  n_exons  length  \n",
       "141862            None                  None        1     957  \n",
       "141863            None                  None        2     290  \n",
       "141865            None                  None        1     543  \n",
       "141866            None                  None        1    1182  \n",
       "141867            None                  None        1     206  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.annot_gene_id.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b8f4e-b353-4a36-aa72-5e7c885fa85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376871f-6580-4a02-8ff5-536f559cd227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "899c2101-7ce7-4d17-91bb-127dadd14613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get novelty types of genes\n",
    "g_df, g_dict = get_gene_novs(db)\n",
    "\n",
    "# get novelty types of transcripts\n",
    "t_df, t_dict = get_transcript_novs(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6eb00-f12f-4b58-84a6-016a3584b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ceb556-2bf7-49ef-80ce-14e73a57f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whitelist = putils.handle_filtering(db, \n",
    "#                             annot, \n",
    "#                             False, \n",
    "#                             pass_list, \n",
    "#                             None)\n",
    "whitelist = handle_filtering(db, \n",
    "                            annot, \n",
    "                            False, \n",
    "                            pass_list, \n",
    "                            dataset_file)\n",
    "\n",
    "datasets = fetch_dataset_list(dataset_file, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26abd5a1-9f74-4eb4-abd3-50c7c681a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = [ x[1] for x in whitelist ]\n",
    "transcript_str = format_for_IN(transcripts)\n",
    "dataset_str = format_for_IN(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "709d48be-ef8b-4bb8-a7e5-41db90b2f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data\n",
    "with sqlite3.connect(db) as conn:\n",
    "    query = f\"\"\"SELECT transcript_ID, dataset, count\n",
    "                FROM abundance WHERE transcript_ID in {transcript_str}\n",
    "                AND dataset in {dataset_str}\n",
    "             \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedb996a-3c41-4388-9d65-c22b9c3fedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pivot(index='dataset', columns='transcript_ID', values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b0e771-99a1-4ea5-809d-c5ea42bdfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "obs_col = 'dataset'\n",
    "var_col = 'transcript_ID'\n",
    "\n",
    "obs_cat = CategoricalDtype(sorted(df[obs_col].unique()), ordered=True)\n",
    "var_cat = CategoricalDtype(sorted(df[var_col].unique()), ordered=True)\n",
    "\n",
    "row = df[obs_col].astype(obs_cat).cat.codes\n",
    "col = df[var_col].astype(var_cat).cat.codes\n",
    "X = csr_matrix((df['count'], (row, col)), \\\n",
    "               shape=(obs_cat.categories.size,\n",
    "                      var_cat.categories.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac981e0c-f968-4703-b0b1-bff1e6e50087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9561x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9590 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fda68524-4431-4407-998a-870b91da796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.sparse.from_spmatrix(X, \\\n",
    "                         index=obs_cat.categories, \\\n",
    "                         columns=var_cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51a4b442-9604-402b-a3bf-adeac895ccb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>141732</th>\n",
       "      <th>152466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACATCGAAACATCGTCACTTTA-ont_2ka</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATCGAACAACCAATTCATGG-ont_2ka</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATCGAACAACCAGACCTTTC-pb</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATCGAACAACCAGCTCGCGG-ont_2ka</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACATCGAACCGAGATCACTTTA-ont_2ka</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTCACGCATCTTCACACGTTCGAG-ont_2kb</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTCACGCATCTTCACAGCTCGCGG-ont_2kb</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTCACGCATCTTCACATCACTTTA-ont_2kb</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTCACGCATGAAGAGAACTATATA-ont_2ka</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTCACGCATTCACGCAATCGCATA-ont_2kb</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9561 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  141732  152466\n",
       "AAACATCGAAACATCGTCACTTTA-ont_2ka       1       0\n",
       "AAACATCGAACAACCAATTCATGG-ont_2ka       1       0\n",
       "AAACATCGAACAACCAGACCTTTC-pb            1       0\n",
       "AAACATCGAACAACCAGCTCGCGG-ont_2ka       4       0\n",
       "AAACATCGAACCGAGATCACTTTA-ont_2ka       1       0\n",
       "...                                  ...     ...\n",
       "TTCACGCATCTTCACACGTTCGAG-ont_2kb       1       0\n",
       "TTCACGCATCTTCACAGCTCGCGG-ont_2kb       7       0\n",
       "TTCACGCATCTTCACATCACTTTA-ont_2kb       1       0\n",
       "TTCACGCATGAAGAGAACTATATA-ont_2ka       1       0\n",
       "TTCACGCATTCACGCAATCGCATA-ont_2kb       3       0\n",
       "\n",
       "[9561 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "664cf26f-6ee4-44dc-81bf-1e0cd3e7898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACATCGAAACATCGTCACTTTA-ont_2ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACATCGAACAACCAATTCATGG-ont_2ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACATCGAACAACCAGACCTTTC-pb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACATCGAACAACCAGCTCGCGG-ont_2ka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACATCGAACCGAGATCACTTTA-ont_2ka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset\n",
       "0  AAACATCGAAACATCGTCACTTTA-ont_2ka\n",
       "1  AAACATCGAACAACCAATTCATGG-ont_2ka\n",
       "2       AAACATCGAACAACCAGACCTTTC-pb\n",
       "3  AAACATCGAACAACCAGCTCGCGG-ont_2ka\n",
       "4  AAACATCGAACCGAGATCACTTTA-ont_2ka"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obs\n",
    "obs = pd.DataFrame(data=obs_cat.categories.tolist(), columns=['dataset'])\n",
    "obs.head()\n",
    "\n",
    "# get information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ded7c6f-2cb3-45bb-a21c-e617f90fedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var\n",
    "var = pd.DataFrame(data=var_cat.categories.tolist(), columns=['transcript_ID'])\n",
    "var.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4780f6e4-57c0-45b0-8cff-8c3911384626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_ID</th>\n",
       "      <th>transcript_ID</th>\n",
       "      <th>annot_gene_id</th>\n",
       "      <th>annot_transcript_id</th>\n",
       "      <th>annot_gene_name</th>\n",
       "      <th>annot_transcript_name</th>\n",
       "      <th>n_exons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSMUSG00000102693.1</td>\n",
       "      <td>ENSMUST00000193812.1</td>\n",
       "      <td>4933401J01Rik</td>\n",
       "      <td>4933401J01Rik-201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSMUSG00000064842.1</td>\n",
       "      <td>ENSMUST00000082908.1</td>\n",
       "      <td>Gm26206</td>\n",
       "      <td>Gm26206-201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000162897.1</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000159265.1</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-202</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>ENSMUSG00000051951.5</td>\n",
       "      <td>ENSMUST00000070533.4</td>\n",
       "      <td>Xkr4</td>\n",
       "      <td>Xkr4-201</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459168</th>\n",
       "      <td>7245</td>\n",
       "      <td>2459169</td>\n",
       "      <td>ENSMUSG00000027589.14</td>\n",
       "      <td>None</td>\n",
       "      <td>Pcmtd2</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459170</th>\n",
       "      <td>7245</td>\n",
       "      <td>2459171</td>\n",
       "      <td>ENSMUSG00000027589.14</td>\n",
       "      <td>None</td>\n",
       "      <td>Pcmtd2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459171</th>\n",
       "      <td>7245</td>\n",
       "      <td>2459172</td>\n",
       "      <td>ENSMUSG00000027589.14</td>\n",
       "      <td>None</td>\n",
       "      <td>Pcmtd2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459174</th>\n",
       "      <td>7246</td>\n",
       "      <td>2459175</td>\n",
       "      <td>ENSMUSG00000038628.8</td>\n",
       "      <td>None</td>\n",
       "      <td>Polr3k</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459175</th>\n",
       "      <td>7246</td>\n",
       "      <td>2459176</td>\n",
       "      <td>ENSMUSG00000038628.8</td>\n",
       "      <td>None</td>\n",
       "      <td>Polr3k</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1814604 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gene_ID  transcript_ID          annot_gene_id   annot_transcript_id  \\\n",
       "0              1              1   ENSMUSG00000102693.1  ENSMUST00000193812.1   \n",
       "1              2              2   ENSMUSG00000064842.1  ENSMUST00000082908.1   \n",
       "2              3              3   ENSMUSG00000051951.5  ENSMUST00000162897.1   \n",
       "3              3              4   ENSMUSG00000051951.5  ENSMUST00000159265.1   \n",
       "4              3              5   ENSMUSG00000051951.5  ENSMUST00000070533.4   \n",
       "...          ...            ...                    ...                   ...   \n",
       "2459168     7245        2459169  ENSMUSG00000027589.14                  None   \n",
       "2459170     7245        2459171  ENSMUSG00000027589.14                  None   \n",
       "2459171     7245        2459172  ENSMUSG00000027589.14                  None   \n",
       "2459174     7246        2459175   ENSMUSG00000038628.8                  None   \n",
       "2459175     7246        2459176   ENSMUSG00000038628.8                  None   \n",
       "\n",
       "        annot_gene_name annot_transcript_name  n_exons  \n",
       "0         4933401J01Rik     4933401J01Rik-201        1  \n",
       "1               Gm26206           Gm26206-201        1  \n",
       "2                  Xkr4              Xkr4-203        2  \n",
       "3                  Xkr4              Xkr4-202        2  \n",
       "4                  Xkr4              Xkr4-201        3  \n",
       "...                 ...                   ...      ...  \n",
       "2459168          Pcmtd2                  None        4  \n",
       "2459170          Pcmtd2                  None        1  \n",
       "2459171          Pcmtd2                  None        1  \n",
       "2459174          Polr3k                  None        2  \n",
       "2459175          Polr3k                  None        4  \n",
       "\n",
       "[1814604 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df.annot_gene_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f4460-17b5-4bcb-a3a3-fbd64b671751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
